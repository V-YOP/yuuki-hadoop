# 需创建名为my_network的网络，172.19.0.0/16
# 这里没有绑定端口，因为直接访问容器的IP最方便
version: '3.8'

networks:
  yuuki.net:
    external: true

# hadoop1: NameNode, DataNode           |  NodeManager
# hadoop2: DataNode                     |  ResourceManager, NodeManager
# hadoop3: SecondaryNameNode, DataNode  |  NodeManager
# hadoop4: DataNode                     |  NodeManager
# 可以注意到，每个机器上都有DataNode和NodeManager，而NameNode，ResourceManager，SecondaryNameNode只有一个
# 当然，它也可以不只有一个，使用高可用配置能让Namenode具有热备份，从而消除单点故障的存在（好耶！）
# 问题：NameNode和ResourceManager是如何标识的？配置文件？执行hdfs namenode -format的机器？启动start-dfs.sh，start-yarn.sh的机器？
services:  
  hdp1.local:
    stdin_open: true 
    tty: true 
    build: .
    hostname:  hdp1.local
    container_name:  hdp1.local
    volumes:
      - ./share/:/share
    networks:
      yuuki.net:
        ipv4_address: 172.19.2.1
  hdp2.local:
    stdin_open: true 
    tty: true 
    build: .
    hostname: hdp2.local
    container_name: hdp2.local
    volumes:
      - ./share/:/share
    networks:
      yuuki.net:
        ipv4_address: 172.19.2.2
  hdp3.local:
    stdin_open: true 
    tty: true 
    build: .
    hostname: hdp3.local
    container_name: hdp3.local
    volumes:
      - ./share/:/share
    networks:
      yuuki.net:
        ipv4_address: 172.19.2.3
  hive.local:
    stdin_open: true 
    tty: true 
    build: .
    hostname: hive.local
    container_name: hive.local
    volumes:
      - ./share/:/share
    networks:
      yuuki.net:
        ipv4_address: 172.19.2.4
  mysql:
    image: mysql
    hostname: db.local
    container_name : db.local
    networks:
      yuuki.net:
        ipv4_address: 172.19.2.5
    environment:
      MYSQL_ROOT_PASSWORD : 123456
  spark.local:
    stdin_open: true 
    tty: true 
    build: .
    hostname: spark.local
    container_name: spark.local
    volumes:
      - ./share/:/share
    networks:
      yuuki.net:
        ipv4_address: 172.19.2.6